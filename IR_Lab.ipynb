{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2: IR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Basic Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparations:\n",
    "* Download the provided dataset **DSS_Fall2017_Assign1.zip** and extract it to a local folder (e.g., C:\\DSS_Fall2017_Assign1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MATERIALS_DIR = r\"C:\\DSS_Fall2017_Assign2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Import necessary libraries: whoosh(for IR) and os,shutil(for working with files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from whoosh import index, writing\n",
    "from whoosh.fields import Schema, TEXT, KEYWORD, ID, STORED\n",
    "from whoosh.analysis import *\n",
    "from whoosh.qparser import QueryParser\n",
    "import os, os.path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DOCUMENTS_DIR = os.path.join(MATERIALS_DIR, r\"DSS_Fall2017_Assign2\\lab1-q1-test-collection\\documents\")\n",
    "INDEX_DIR = os.path.join(MATERIALS_DIR, r\"DSS_Fall2017_Assign2\\lab1-q1-test-collection\\index1\")\n",
    "QUER_FILE = os.path.join(MATERIALS_DIR, r\"DSS_Fall2017_Assign2\\lab1-q1-test-collection\\topics\\air.topics\")\n",
    "QRELS_FILE = os.path.join(MATERIALS_DIR, r\"DSS_Fall2017_Assign2\\lab1-q1-test-collection\\qrels\\air.qrels\")\n",
    "OUTPUT_FILE = os.path.join(MATERIALS_DIR, r\"DSS_Fall2017_Assign2\\lab1-q1-test-collection\\myres\")\n",
    "TREC_EVAL = os.path.join(MATERIALS_DIR, r\"DSS_Fall2017_Assign2\\trec_eval\\trec_eval.exe\")\n",
    "INDEX_DIR2 = os.path.join(MATERIALS_DIR, r\"DSS_Fall2017_Assign2\\lab1-q1-test-collection\\index2\")\n",
    "OUTPUT_FILE2 = os.path.join(MATERIALS_DIR, r\"DSS_Fall2017_Assign2\\lab1-q1-test-collection\\myres2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first, define a Schema for the index\n",
    "mySchema = Schema(file_path = ID(stored=True),\n",
    "                  file_content = TEXT(analyzer = RegexTokenizer()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if index exists - remove it\n",
    "if os.path.isdir(INDEX_DIR):\n",
    "    shutil.rmtree(INDEX_DIR)\n",
    "\n",
    "# create the directory for the index\n",
    "os.makedirs(INDEX_DIR)\n",
    "\n",
    "# create index\n",
    "myIndex = index.create_in(INDEX_DIR, mySchema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is 10DF-697A\n",
      "\n",
      " Directory of C:\\DSS_Fall2017_Assign2\\DSS_Fall2017_Assign2\\lab1-q1-test-collection\\documents\n",
      "\n",
      "09/29/2017  12:39 PM    <DIR>          .\n",
      "09/29/2017  12:39 PM    <DIR>          ..\n",
      "09/29/2017  12:39 PM            19,703 email01\n",
      "09/29/2017  12:39 PM            19,844 email02\n",
      "09/29/2017  12:39 PM            19,059 email03\n",
      "09/29/2017  12:39 PM            19,548 email04\n",
      "09/29/2017  12:39 PM            16,693 email05\n",
      "09/29/2017  12:39 PM            20,332 email06\n",
      "09/29/2017  12:39 PM            19,995 email07\n",
      "09/29/2017  12:39 PM            18,075 email08\n",
      "09/29/2017  12:39 PM            18,621 email09\n",
      "09/29/2017  12:39 PM            19,884 email10\n",
      "09/29/2017  12:39 PM            18,336 email14\n",
      "              11 File(s)        210,090 bytes\n",
      "               2 Dir(s)  66,223,439,872 bytes free\n"
     ]
    }
   ],
   "source": [
    "# First, lets review the documents in our sample dataset\n",
    "!dir $DOCUMENTS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first we build a list of all the full paths of the files in DOCUMENTS_DIR\n",
    "filesToIndex = []\n",
    "for root, dirs, files in os.walk(DOCUMENTS_DIR):\n",
    "    filePaths = [os.path.join(root, fileName) for fileName in files if not fileName.startswith('.')]\n",
    "    filesToIndex.extend(filePaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\DSS_Fall2017_Assign2\\DSS_Fall2017_Assign2\\lab1-q1-test-collection\\documents\\email01\n",
      "C:\\DSS_Fall2017_Assign2\\DSS_Fall2017_Assign2\\lab1-q1-test-collection\\documents\\email02\n",
      "C:\\DSS_Fall2017_Assign2\\DSS_Fall2017_Assign2\\lab1-q1-test-collection\\documents\\email03\n",
      "C:\\DSS_Fall2017_Assign2\\DSS_Fall2017_Assign2\\lab1-q1-test-collection\\documents\\email04\n",
      "C:\\DSS_Fall2017_Assign2\\DSS_Fall2017_Assign2\\lab1-q1-test-collection\\documents\\email05\n"
     ]
    }
   ],
   "source": [
    "# print the first 5 paths to make sure it worked\n",
    "print(\"\\n\".join(filesToIndex[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of files: 11\n"
     ]
    }
   ],
   "source": [
    "# count files to index\n",
    "print(\"number of files:\", len(filesToIndex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already indexed: 1\n",
      "done indexing.\n"
     ]
    }
   ],
   "source": [
    "# open writer\n",
    "myWriter = writing.BufferedWriter(myIndex, period=20, limit=1000)\n",
    "\n",
    "try:\n",
    "    # write each file to index\n",
    "    for docNum, filePath in enumerate(filesToIndex):\n",
    "        with open(filePath, \"r\") as f:\n",
    "            fileContent = f.read()\n",
    "            myWriter.add_document(file_path = filePath,\n",
    "                                  file_content = fileContent)\n",
    "            \n",
    "            if (docNum % 1000 == 0):\n",
    "                print(\"already indexed:\", docNum+1)\n",
    "    print(\"done indexing.\")\n",
    "\n",
    "finally:\n",
    "    # save the index\n",
    "    myWriter.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a query parser for the field \"file_content\" in the index\n",
    "myQueryParser = QueryParser(\"file_content\", schema=myIndex.schema)\n",
    "mySearcher = myIndex.searcher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "email01 0 2.6746417187049216\n"
     ]
    }
   ],
   "source": [
    "# run a sample query for the phrase \"item\"\n",
    "sampleQuery = myQueryParser.parse(\"item\")\n",
    "sampleQueryResults = mySearcher.search(sampleQuery, limit=None)\n",
    "\n",
    "# inspect the result:\n",
    "# for each document print the rank and the score\n",
    "for (docnum, result) in enumerate(sampleQueryResults):\n",
    "    score = sampleQueryResults.score(docnum)\n",
    "    fileName = os.path.basename(result[\"file_path\"])\n",
    "    print(fileName, docnum, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation using TREC_EVAL\n",
    "In order to evaluate our results we will use a topic file - a list of topics we use to evaluate our IR system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01 ducks\n",
      "02 ig nobel prizes\n",
      "03 mathematics\n",
      "04 flowing hair\n",
      "05 music\n",
      "06 AIR TV\n"
     ]
    }
   ],
   "source": [
    "# print the topic file\n",
    "!cat $QUER_FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will compare our evaluate our results with a set of judged results(qrels file) using TREC_EVAL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01 0 email01 0\n",
      "01 0 email02 0\n",
      "01 0 email03 0\n",
      "01 0 email04 1\n",
      "01 0 email05 1\n",
      "01 0 email06 1\n",
      "01 0 email07 0\n",
      "01 0 email08 0\n",
      "01 0 email09 0\n",
      "01 0 email10 0\n"
     ]
    }
   ],
   "source": [
    "# print the first 10 lines in the qrels file\n",
    "!head -n 10 $QRELS_FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we build a file with our results accoring to TREC_EVAL format (see assignment PDF for more details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load topic file - a list of topics(search phrases) used for evalutation\n",
    "topicsFile = open(QUER_FILE,\"r\")\n",
    "topics = topicsFile.read().splitlines()\n",
    "\n",
    "# create an output file to which we'll write our results\n",
    "outputTRECFile = open(OUTPUT_FILE, \"w\")\n",
    "\n",
    "# for each evaluated topic:\n",
    "# build a query and record the results in the file in TREC_EVAL format\n",
    "for topic in topics:\n",
    "    topic_id, topic_phrase = tuple(topic.split(\" \", 1))\n",
    "    topicQuery = myQueryParser.parse(topic_phrase)\n",
    "    topicResults = mySearcher.search(topicQuery, limit=None)\n",
    "    for (docnum, result) in enumerate(topicResults):\n",
    "        score = topicResults.score(docnum)\n",
    "        outputTRECFile.write(\"%s Q0 %s %d %lf test\\n\" % (topic_id, os.path.basename(result[\"file_path\"]), docnum, score))\n",
    "\n",
    "# close the topic and results file\n",
    "outputTRECFile.close()\n",
    "topicsFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we use TREC_EVAL to compare our results with the provided qrels file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'$TREC_EVAL' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!$TREC_EVAL -q -m recip_rank $QRELS_FILE $OUTPUT_FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part b. Evaluating different configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting our index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index is empty? False\n",
      "Number of indexed files: 11\n"
     ]
    }
   ],
   "source": [
    "# Is it empty?\n",
    "print(\"Index is empty?\", myIndex.is_empty())\n",
    "\n",
    "# How many files indexed?\n",
    "print(\"Number of indexed files:\", myIndex.doc_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a reader object on the index\n",
    "myReader = myIndex.reader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  {'file_path': 'C:\\\\DSS_Fall2017_Assign2\\\\DSS_Fall2017_Assign2\\\\lab1-q1-test-collection\\\\documents\\\\email01'}),\n",
       " (1,\n",
       "  {'file_path': 'C:\\\\DSS_Fall2017_Assign2\\\\DSS_Fall2017_Assign2\\\\lab1-q1-test-collection\\\\documents\\\\email02'}),\n",
       " (2,\n",
       "  {'file_path': 'C:\\\\DSS_Fall2017_Assign2\\\\DSS_Fall2017_Assign2\\\\lab1-q1-test-collection\\\\documents\\\\email03'}),\n",
       " (3,\n",
       "  {'file_path': 'C:\\\\DSS_Fall2017_Assign2\\\\DSS_Fall2017_Assign2\\\\lab1-q1-test-collection\\\\documents\\\\email04'}),\n",
       " (4,\n",
       "  {'file_path': 'C:\\\\DSS_Fall2017_Assign2\\\\DSS_Fall2017_Assign2\\\\lab1-q1-test-collection\\\\documents\\\\email05'})]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print first 5 indexed documents\n",
    "[(docnum, doc_dict) for (docnum, doc_dict) in myReader.iter_docs()][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Care',\n",
       " 'Carlos',\n",
       " 'Carmen',\n",
       " 'Carnivalesque',\n",
       " 'Carolina',\n",
       " 'Case',\n",
       " 'Cat',\n",
       " 'Catalysis',\n",
       " 'Catalyst',\n",
       " 'Catchers',\n",
       " 'Cater',\n",
       " 'Caused',\n",
       " 'Caveat',\n",
       " 'CbZF1d0021swQuc57kfqHt',\n",
       " 'Cechetto',\n",
       " 'Ceder',\n",
       " 'Celebratory',\n",
       " 'Center',\n",
       " 'Cereal',\n",
       " 'Ceremony',\n",
       " 'Cerrahi',\n",
       " 'Certolizumab',\n",
       " 'Cervical',\n",
       " 'Chair',\n",
       " 'Chalfie']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list indexed terms for field \"file_content\"\n",
    "[term for term in myReader.field_terms(\"file_content\")][1000:1025]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29729\n"
     ]
    }
   ],
   "source": [
    "#how many terms do we have?\n",
    "print(myReader.field_length(\"file_content\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# docs with 'bit' 1\n",
      "# docs with 'are' 11\n",
      "# docs with 'get' 6\n"
     ]
    }
   ],
   "source": [
    "# how many documents have the phrases \"bit\", blob\"\n",
    "#   in the field \"file_content\"?\n",
    "print(\"# docs with 'bit'\", myReader.doc_frequency(\"file_content\", \"bit\"))\n",
    "print(\"# docs with 'are'\", myReader.doc_frequency(\"file_content\", \"are\"))\n",
    "print(\"# docs with 'get'\", myReader.doc_frequency(\"file_content\", \"get\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Analyzers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We',\n",
       " 'are',\n",
       " 'going',\n",
       " 'to',\n",
       " 'do',\n",
       " 'Text',\n",
       " 'Analysis',\n",
       " 'with',\n",
       " 'whoosh.analysis']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we start with basic tokenizer\n",
    "tokenizer = RegexTokenizer()\n",
    "[token.text for token in tokenizer(\"We are going to do Text Analysis with whoosh.analysis\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We', 'ar', 'go', 'to', 'do', 'Text', 'Analysi', 'with', 'whoosh.analysi']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we might want use stemming:\n",
    "stmAnalyzer = RegexTokenizer() | StemFilter()\n",
    "[token.text for token in stmAnalyzer(\"We are going to do Text Analysis with whoosh.analysis\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['we', 'ar', 'go', 'to', 'do', 'text', 'analysi', 'with', 'whoosh.analysi']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We probably want to lower-case it\n",
    "# so we add LowercaseFilter\n",
    "stmLwrAnalyzer = RegexTokenizer() | LowercaseFilter() | StemFilter()\n",
    "[token.text for token in stmLwrAnalyzer(\"We are going to do Text Analysis with whoosh.analysis\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go', 'do', 'text', 'analysi', 'whoosh.analysi']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we probably want to ignore words like \"we\", \"are\", \"with\" when we index files\n",
    "# so we add StopFilter to filter stop words\n",
    "stmLwrStpAnalyzer = RegexTokenizer() | LowercaseFilter() | StopFilter() | StemFilter()\n",
    "[token.text for token in stmLwrStpAnalyzer(\"We are going to do Text Analysis with whoosh.analysis\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go', 'do', 'text', 'analysi', 'whoosh', 'analysi']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we also probably want to break phrases like \"whoosh.analysis\" into \"whoosh\" and \"analysis\"\n",
    "# so we add IntraWordFilter\n",
    "stmLwrStpIntraAnalyzer = RegexTokenizer() | LowercaseFilter() | IntraWordFilter() | StopFilter() | StemFilter()\n",
    "[token.text for token in stmLwrStpIntraAnalyzer(\"We are going to do Text Analysis with whoosh.analysis\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the new analyzers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mySchema2 = Schema(file_path = ID(stored=True),\n",
    "                   file_content = TEXT(analyzer = stmLwrStpIntraAnalyzer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if index exists - remove it\n",
    "if os.path.isdir(INDEX_DIR2):\n",
    "    shutil.rmtree(INDEX_DIR2)\n",
    "\n",
    "# create the directory for the index\n",
    "os.makedirs(INDEX_DIR2)\n",
    "\n",
    "# create index or open it if already exists\n",
    "myIndex2 = index.create_in(INDEX_DIR2, mySchema2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already indexed: 1\n",
      "done indexing.\n"
     ]
    }
   ],
   "source": [
    "# open writer\n",
    "myWriter2 = writing.BufferedWriter(myIndex2, period=20, limit=1000)\n",
    "\n",
    "try:\n",
    "    # write each file to index\n",
    "    for docNum, filePath in enumerate(filesToIndex):\n",
    "        with open(filePath, \"r\") as f:\n",
    "            fileContent = f.read()\n",
    "            myWriter2.add_document(file_path = filePath,\n",
    "                                  file_content = fileContent)\n",
    "            \n",
    "            if (docNum % 1000 == 0):\n",
    "                print(\"already indexed:\", docNum+1)\n",
    "    print(\"done indexing.\")\n",
    "\n",
    "finally:\n",
    "    # save the index\n",
    "    myWriter2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a query parser for the field \"file_content\" in the index\n",
    "myQueryParser2 = QueryParser(\"file_content\", schema=myIndex2.schema)\n",
    "mySearcher2 = myIndex2.searcher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load topic file - a list of topics(search phrases) used for evalutation\n",
    "topicsFile = open(QUER_FILE,\"r\")\n",
    "topics = topicsFile.read().splitlines()\n",
    "\n",
    "# create an output file to which we'll write our results\n",
    "outputTRECFile2 = open(OUTPUT_FILE2, \"w\")\n",
    "\n",
    "# for each evaluated topic:\n",
    "# build a query and record the results in the file in TREC_EVAL format\n",
    "for topic in topics:\n",
    "    topic_id, topic_phrase = tuple(topic.split(\" \", 1))\n",
    "    topicQuery = myQueryParser2.parse(topic_phrase)\n",
    "    topicResults = mySearcher2.search(topicQuery, limit=None)\n",
    "    for (docnum, result) in enumerate(topicResults):\n",
    "        score = topicResults.score(docnum)\n",
    "        outputTRECFile2.write(\"%s Q0 %s %d %lf test\\n\" % (topic_id, os.path.basename(result[\"file_path\"]), docnum, score))\n",
    "\n",
    "# close the topic and results file\n",
    "outputTRECFile2.close()\n",
    "topicsFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_ret               \t01\t3\n",
      "num_rel               \t01\t3\n",
      "num_rel_ret           \t01\t3\n",
      "map                   \t01\t1.0000\n",
      "Rprec                 \t01\t1.0000\n",
      "bpref                 \t01\t1.0000\n",
      "recip_rank            \t01\t1.0000\n",
      "iprec_at_recall_0.00  \t01\t1.0000\n",
      "iprec_at_recall_0.10  \t01\t1.0000\n",
      "iprec_at_recall_0.20  \t01\t1.0000\n",
      "iprec_at_recall_0.30  \t01\t1.0000\n",
      "iprec_at_recall_0.40  \t01\t1.0000\n",
      "iprec_at_recall_0.50  \t01\t1.0000\n",
      "iprec_at_recall_0.60  \t01\t1.0000\n",
      "iprec_at_recall_0.70  \t01\t1.0000\n",
      "iprec_at_recall_0.80  \t01\t1.0000\n",
      "iprec_at_recall_0.90  \t01\t1.0000\n",
      "iprec_at_recall_1.00  \t01\t1.0000\n",
      "P_5                   \t01\t0.6000\n",
      "P_10                  \t01\t0.3000\n",
      "P_15                  \t01\t0.2000\n",
      "P_20                  \t01\t0.1500\n",
      "P_30                  \t01\t0.1000\n",
      "P_100                 \t01\t0.0300\n",
      "P_200                 \t01\t0.0150\n",
      "P_500                 \t01\t0.0060\n",
      "P_1000                \t01\t0.0030\n",
      "num_ret               \t02\t11\n",
      "num_rel               \t02\t8\n",
      "num_rel_ret           \t02\t8\n",
      "map                   \t02\t0.9207\n",
      "Rprec                 \t02\t0.8750\n",
      "bpref                 \t02\t0.7500\n",
      "recip_rank            \t02\t1.0000\n",
      "iprec_at_recall_0.00  \t02\t1.0000\n",
      "iprec_at_recall_0.10  \t02\t1.0000\n",
      "iprec_at_recall_0.20  \t02\t1.0000\n",
      "iprec_at_recall_0.30  \t02\t1.0000\n",
      "iprec_at_recall_0.40  \t02\t1.0000\n",
      "iprec_at_recall_0.50  \t02\t1.0000\n",
      "iprec_at_recall_0.60  \t02\t0.8750\n",
      "iprec_at_recall_0.70  \t02\t0.8750\n",
      "iprec_at_recall_0.80  \t02\t0.8750\n",
      "iprec_at_recall_0.90  \t02\t0.8000\n",
      "iprec_at_recall_1.00  \t02\t0.8000\n",
      "P_5                   \t02\t0.8000\n",
      "P_10                  \t02\t0.8000\n",
      "P_15                  \t02\t0.5333\n",
      "P_20                  \t02\t0.4000\n",
      "P_30                  \t02\t0.2667\n",
      "P_100                 \t02\t0.0800\n",
      "P_200                 \t02\t0.0400\n",
      "P_500                 \t02\t0.0160\n",
      "P_1000                \t02\t0.0080\n",
      "num_ret               \t03\t2\n",
      "num_rel               \t03\t1\n",
      "num_rel_ret           \t03\t1\n",
      "map                   \t03\t1.0000\n",
      "Rprec                 \t03\t1.0000\n",
      "bpref                 \t03\t1.0000\n",
      "recip_rank            \t03\t1.0000\n",
      "iprec_at_recall_0.00  \t03\t1.0000\n",
      "iprec_at_recall_0.10  \t03\t1.0000\n",
      "iprec_at_recall_0.20  \t03\t1.0000\n",
      "iprec_at_recall_0.30  \t03\t1.0000\n",
      "iprec_at_recall_0.40  \t03\t1.0000\n",
      "iprec_at_recall_0.50  \t03\t1.0000\n",
      "iprec_at_recall_0.60  \t03\t1.0000\n",
      "iprec_at_recall_0.70  \t03\t1.0000\n",
      "iprec_at_recall_0.80  \t03\t1.0000\n",
      "iprec_at_recall_0.90  \t03\t1.0000\n",
      "iprec_at_recall_1.00  \t03\t1.0000\n",
      "P_5                   \t03\t0.2000\n",
      "P_10                  \t03\t0.1000\n",
      "P_15                  \t03\t0.0667\n",
      "P_20                  \t03\t0.0500\n",
      "P_30                  \t03\t0.0333\n",
      "P_100                 \t03\t0.0100\n",
      "P_200                 \t03\t0.0050\n",
      "P_500                 \t03\t0.0020\n",
      "P_1000                \t03\t0.0010\n",
      "num_ret               \t04\t8\n",
      "num_rel               \t04\t5\n",
      "num_rel_ret           \t04\t5\n",
      "map                   \t04\t0.8393\n",
      "Rprec                 \t04\t0.6000\n",
      "bpref                 \t04\t0.8400\n",
      "recip_rank            \t04\t1.0000\n",
      "iprec_at_recall_0.00  \t04\t1.0000\n",
      "iprec_at_recall_0.10  \t04\t1.0000\n",
      "iprec_at_recall_0.20  \t04\t1.0000\n",
      "iprec_at_recall_0.30  \t04\t1.0000\n",
      "iprec_at_recall_0.40  \t04\t1.0000\n",
      "iprec_at_recall_0.50  \t04\t1.0000\n",
      "iprec_at_recall_0.60  \t04\t1.0000\n",
      "iprec_at_recall_0.70  \t04\t0.6250\n",
      "iprec_at_recall_0.80  \t04\t0.6250\n",
      "iprec_at_recall_0.90  \t04\t0.6250\n",
      "iprec_at_recall_1.00  \t04\t0.6250\n",
      "P_5                   \t04\t0.6000\n",
      "P_10                  \t04\t0.5000\n",
      "P_15                  \t04\t0.3333\n",
      "P_20                  \t04\t0.2500\n",
      "P_30                  \t04\t0.1667\n",
      "P_100                 \t04\t0.0500\n",
      "P_200                 \t04\t0.0250\n",
      "P_500                 \t04\t0.0100\n",
      "P_1000                \t04\t0.0050\n",
      "num_ret               \t05\t2\n",
      "num_rel               \t05\t2\n",
      "num_rel_ret           \t05\t0\n",
      "map                   \t05\t0.0000\n",
      "Rprec                 \t05\t0.0000\n",
      "bpref                 \t05\t0.0000\n",
      "recip_rank            \t05\t0.0000\n",
      "iprec_at_recall_0.00  \t05\t0.0000\n",
      "iprec_at_recall_0.10  \t05\t0.0000\n",
      "iprec_at_recall_0.20  \t05\t0.0000\n",
      "iprec_at_recall_0.30  \t05\t0.0000\n",
      "iprec_at_recall_0.40  \t05\t0.0000\n",
      "iprec_at_recall_0.50  \t05\t0.0000\n",
      "iprec_at_recall_0.60  \t05\t0.0000\n",
      "iprec_at_recall_0.70  \t05\t0.0000\n",
      "iprec_at_recall_0.80  \t05\t0.0000\n",
      "iprec_at_recall_0.90  \t05\t0.0000\n",
      "iprec_at_recall_1.00  \t05\t0.0000\n",
      "P_5                   \t05\t0.0000\n",
      "P_10                  \t05\t0.0000\n",
      "P_15                  \t05\t0.0000\n",
      "P_20                  \t05\t0.0000\n",
      "P_30                  \t05\t0.0000\n",
      "P_100                 \t05\t0.0000\n",
      "P_200                 \t05\t0.0000\n",
      "P_500                 \t05\t0.0000\n",
      "P_1000                \t05\t0.0000\n",
      "num_ret               \t06\t3\n",
      "num_rel               \t06\t2\n",
      "num_rel_ret           \t06\t2\n",
      "map                   \t06\t0.8333\n",
      "Rprec                 \t06\t0.5000\n",
      "bpref                 \t06\t1.0000\n",
      "recip_rank            \t06\t1.0000\n",
      "iprec_at_recall_0.00  \t06\t1.0000\n",
      "iprec_at_recall_0.10  \t06\t1.0000\n",
      "iprec_at_recall_0.20  \t06\t1.0000\n",
      "iprec_at_recall_0.30  \t06\t1.0000\n",
      "iprec_at_recall_0.40  \t06\t1.0000\n",
      "iprec_at_recall_0.50  \t06\t1.0000\n",
      "iprec_at_recall_0.60  \t06\t0.6667\n",
      "iprec_at_recall_0.70  \t06\t0.6667\n",
      "iprec_at_recall_0.80  \t06\t0.6667\n",
      "iprec_at_recall_0.90  \t06\t0.6667\n",
      "iprec_at_recall_1.00  \t06\t0.6667\n",
      "P_5                   \t06\t0.4000\n",
      "P_10                  \t06\t0.2000\n",
      "P_15                  \t06\t0.1333\n",
      "P_20                  \t06\t0.1000\n",
      "P_30                  \t06\t0.0667\n",
      "P_100                 \t06\t0.0200\n",
      "P_200                 \t06\t0.0100\n",
      "P_500                 \t06\t0.0040\n",
      "P_1000                \t06\t0.0020\n",
      "runid                 \tall\ttest\n",
      "num_q                 \tall\t6\n",
      "num_ret               \tall\t29\n",
      "num_rel               \tall\t21\n",
      "num_rel_ret           \tall\t19\n",
      "map                   \tall\t0.7656\n",
      "gm_map                \tall\t0.1364\n",
      "Rprec                 \tall\t0.6625\n",
      "bpref                 \tall\t0.7650\n",
      "recip_rank            \tall\t0.8333\n",
      "iprec_at_recall_0.00  \tall\t0.8333\n",
      "iprec_at_recall_0.10  \tall\t0.8333\n",
      "iprec_at_recall_0.20  \tall\t0.8333\n",
      "iprec_at_recall_0.30  \tall\t0.8333\n",
      "iprec_at_recall_0.40  \tall\t0.8333\n",
      "iprec_at_recall_0.50  \tall\t0.8333\n",
      "iprec_at_recall_0.60  \tall\t0.7569\n",
      "iprec_at_recall_0.70  \tall\t0.6944\n",
      "iprec_at_recall_0.80  \tall\t0.6944\n",
      "iprec_at_recall_0.90  \tall\t0.6819\n",
      "iprec_at_recall_1.00  \tall\t0.6819\n",
      "P_5                   \tall\t0.4333\n",
      "P_10                  \tall\t0.3167\n",
      "P_15                  \tall\t0.2111\n",
      "P_20                  \tall\t0.1583\n",
      "P_30                  \tall\t0.1056\n",
      "P_100                 \tall\t0.0317\n",
      "P_200                 \tall\t0.0158\n",
      "P_500                 \tall\t0.0063\n",
      "P_1000                \tall\t0.0032\n"
     ]
    }
   ],
   "source": [
    "!$TREC_EVAL -q $QRELS_FILE $OUTPUT_FILE2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# docs with 'bit' 11\n",
      "# docs with 'are' 0\n",
      "# docs with 'get' 7\n"
     ]
    }
   ],
   "source": [
    "# let count the same words again\n",
    "myReader2 = myIndex2.reader()\n",
    "print(\"# docs with 'bit'\", myReader2.doc_frequency(\"file_content\", \"bit\"))\n",
    "print(\"# docs with 'are'\", myReader2.doc_frequency(\"file_content\", \"are\"))\n",
    "print(\"# docs with 'get'\", myReader2.doc_frequency(\"file_content\", \"get\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Can you explain the differences? **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using NLTK's stemmers and lemmatizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ron_suprun\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download required resources\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we'll compare two stemmers and a lemmatizer\n",
    "lrStem = LancasterStemmer()\n",
    "sbStem = SnowballStemmer(\"english\")\n",
    "wnLemm = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a list of words to compare the stemmers on\n",
    "listWords = [\"going\", \"saying\", \"minimize\", \"maximum\", \n",
    "             \"meeting\", \"files\", \"tries\", \"is\", \"are\", \"beautiful\",\n",
    "             \"summarize\", \"better\", \"dogs\", \"phenomena\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          going              go           going              go\n",
      "            say             say          saying             say\n",
      "          minim           minim        minimize        minimize\n",
      "          maxim         maximum         maximum         maximum\n",
      "           meet            meet         meeting            meet\n",
      "            fil            file            file            file\n",
      "            tri             tri             try             try\n",
      "             is              is              is              be\n",
      "             ar             are             are              be\n",
      "         beauty          beauti       beautiful       beautiful\n",
      "           summ          summar       summarize       summarize\n",
      "            bet          better          better          better\n",
      "            dog             dog             dog             dog\n",
      "       phenomen       phenomena      phenomenon       phenomena\n"
     ]
    }
   ],
   "source": [
    "for word in listWords:\n",
    "    print(\"%15s %15s %15s %15s\" % (lrStem.stem(word),\n",
    "                                   sbStem.stem(word),\n",
    "                                   wnLemm.lemmatize(word),\n",
    "                                   wnLemm.lemmatize(word, 'v')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to use NLTK stemmers / lemmatizers in Whoosh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dont change this! Use it as-is in your code\n",
    "# This filter will run for both the index and the query\n",
    "from whoosh.analysis import Filter\n",
    "class CustomFilter(Filter):\n",
    "    is_morph = True\n",
    "    def __init__(self, filterFunc, *args, **kwargs):\n",
    "        self.customFilter = filterFunc\n",
    "        self.args = args\n",
    "        self.kwargs = kwargs\n",
    "    def __eq__(self):\n",
    "        return (other\n",
    "                and self.__class__ is other.__class__)\n",
    "    def __call__(self, tokens):\n",
    "        for t in tokens:\n",
    "            if t.mode == 'query': # if called by query parser\n",
    "                t.text = self.customFilter(t.text, *self.args, **self.kwargs)\n",
    "                yield t\n",
    "            else: # == 'index' if called by indexer\n",
    "                t.text = self.customFilter(t.text, *self.args, **self.kwargs)\n",
    "                yield t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['we', 'ar', 'going', 'to', 'do', 'text', 'analys', 'with', 'whoosh.analysis']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example1: Whoosh filter for NLTK's LancasterStemmer\n",
    "myFilter1 = RegexTokenizer() | CustomFilter(LancasterStemmer().stem)\n",
    "[token.text for token in myFilter1(\"We are going to do Text Analysis with whoosh.analysis\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We',\n",
       " 'are',\n",
       " 'going',\n",
       " 'to',\n",
       " 'do',\n",
       " 'Text',\n",
       " 'Analysis',\n",
       " 'with',\n",
       " 'whoosh.analysis']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example2: Whoosh filter for NLTK's WordNetLemmatizer\n",
    "myFilter2 = RegexTokenizer() | CustomFilter(WordNetLemmatizer().lemmatize)\n",
    "[token.text for token in myFilter2(\"We are going to do Text Analysis with whoosh.analysis\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We', 'be', 'go', 'to', 'do', 'Text', 'Analysis', 'with', 'whoosh.analysis']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example3: Whoosh filter for NLTK's WordNetLemmatizer for verbs\n",
    "myFilter3 = RegexTokenizer() | CustomFilter(WordNetLemmatizer().lemmatize, 'v')\n",
    "[token.text for token in myFilter3(\"We are going to do Text Analysis with whoosh.analysis\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now use myFilter1/2/3 as part of your Schema\n",
    "\n",
    "------------\n",
    "You can find details of other NLTK Stemmers and Lemmatizers here:\n",
    "\n",
    "http://www.nltk.org/api/nltk.stem.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
